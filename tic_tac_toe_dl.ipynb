{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "positive-temperature",
   "metadata": {},
   "source": [
    "# Tic Tac Toe and Deep Learning\n",
    "## Overview\n",
    "The objective of this notebook is to train an AI agent to play Tic Tac Toe.  The AI Agent knows nothing about Tic Tac Toe, it does not know any of the rules of the game or know that it is even playing a game.  The AI agent will play multiple games of Tic Tac Toe and will learn from it. The Tac Tac Toe game will allow the Agent to play a move on one of the 9 positions on a Tic Tac Toe board.  The game will then check if this position is already filled (therefore invalid move) and if filled, will ask for a new move to be played. If the position is not already filled, the game will check if this leads to a win, if the game has been won, the game gives feedback that it was won. \n",
    "\n",
    "The actual game code is contained in the script <strong>ttt.py</strong>.  The gameplay in <strong>ttt.py</strong> allows for generating game data which will be reformatted in this notebook and used as training data. The actual machine learning code is contained in this Notebook.  The machine learning method that will be used is deep learning.  Using Keras a sequential neural network will be created and then training on gameplay data.  There will be three methods for evaluating the neural network, first the actual training accuracy, then based on the ability to play against an untrained agent and lastly a subjective analysis of the Agent playing against a human.\n",
    "\n",
    "<img src=\"http://d5mit.co.za/images/TTT.gif\">\n",
    "\n",
    "\n",
    "\n",
    "## Approach\n",
    "The process that is followed in this notebook is firstly to explore the data and to understand the concept. The next step is to train Agent S on gameplay data. After that a new Agent will be trained, Agent L, which is an improvement on Agent S' ability to play Tic Tac Toe.  Lastly in the conclusion the AI Agent will be evaluated and it will also allow a human to play against the AI agent.\n",
    "\n",
    "1. [Understanding the concept and exploring the data](#_1)<br>\n",
    "2. [Generate training data and train Agent S](#_2)<br>\n",
    "    2.1 [Create training data](#_21)<br>\n",
    "    2.2 [Train model S](#_22)<br>\n",
    "    2.3 [Agent S evaluation and conclusion](#_23)<br>\n",
    "3. [Generate training data and train Agent L (improvement on Agent S)](#_3)   <br>\n",
    "    3.1 [Create training data](#_31)<br>\n",
    "    3.2 [Train model L](#_32)<br>\n",
    "    3.3 [Agent L evaluation and conclusion](#_33)<br>\n",
    "4. [Conclusion](#_4)<br>\n",
    "    4.1 [Evaluate AI agents](#_41)<br>\n",
    "    4.2 [Play against Agent L](#_42)\n",
    "\n",
    "\n",
    "## Evaluation (Step 3.3)\n",
    "In order to do the final evaluation in step 3.3, an untrained agent played Tic Tac Toe against the trained Agent L. The untrained agent wins and trained agent wins are recorded.<br>\n",
    "\n",
    "<strong>Metric</strong><br>\n",
    "The data provided contains the untrained agent wins and trained agent wins. \n",
    "This is the metric used in order to determine which player is better at playing Tic Tac Toe.\n",
    "<br>\n",
    "\n",
    "<strong>Objective</strong><br>\n",
    "The objective is to check if the trained Agent L is signitifantly better at playing Tic Tac Toe than an untrained Agent. \n",
    "<br>\n",
    "\n",
    "<strong>Hypothesis</strong><br>\n",
    "H0: trained_agent_wins - unrained_agent_wins = 0 <br>\n",
    "H1: trained_agent_wins - unrained_agent_wins > 0    \n",
    "\n",
    "\n",
    "## Parameters\n",
    "The parameters in the cell below manages the notebook in terms of what code is executed and what gameplay files are used in order to train on. This can be changed as required.\n",
    "\n",
    "<strong>Very important!!!!!</strong><br>\n",
    "Setting all these parameters to True in the section below, will lead to the notebook running rather long.<br> \n",
    "- do_gen_ifile_UU -> set to true if untrained agent should play against untrained agent\n",
    "- do_gen_ifile_US -> set to true if untrained agent should play against untrained agent\n",
    "- do_gen_ifile_SS -> set to true if untrained agent should play against agent S\n",
    "- do_gen_ifile_SH -> set to True if agent S should play against agent S \n",
    "- do_train_modelS -> set to True if agent s vs human game should be played\n",
    "- do_train_modelL -> set to True if model S should be trained \n",
    "- do_final_evaluL -> set to True if the final evaluation should be executed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "common-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to run\n",
    "# if you want to run the full notebook with all funtion this must all be set to true.  \n",
    "# Note the notebook can run rather long therefore it is split.\n",
    "do_gen_ifile_UU = True                        # set to true if untrained agent should play against untrained agent\n",
    "do_gen_ifile_US = True                        # set to true if untrained agent should play against agent S\n",
    "do_gen_ifile_SS = True                        # set to True if agent S should play against agent S \n",
    "do_gen_ifile_SH = True                        # set to True if agent s vs human game should be played\n",
    "do_train_modelS = True                        # set to True if model S should be trained         \n",
    "do_train_modelL = True                        # set to True if model L should be trained \n",
    "do_final_evaluL = True                        # set to True if the final evaluation should be executed \n",
    "\n",
    "# you can manually add training files in these lists\n",
    "# Training data files:\n",
    "# untrained vs untrained agent games:\n",
    "ifiles_UU = ['TrainingData/games_played_UU_14022021192742.csv',       \n",
    "             'TrainingData/games_played_UU_14022021193021.csv',\n",
    "             'TrainingData/games_played_UU_14022021200945.csv',\n",
    "             'TrainingData/games_played_UU_14022021201410.csv',\n",
    "             'TrainingData/games_played_UU_14022021201623.csv',\n",
    "             'TrainingData/games_played_UU_14022021202502.csv']\n",
    "\n",
    "# untrained agent vs human game games:\n",
    "ifiles_UH = ['TrainingData/games_played_UH_all.csv']\n",
    "\n",
    "# untrained agent vs agent S games:\n",
    "ifiles_US = ['TrainingData/games_played_US_15022021092905.csv']\n",
    "\n",
    "# agent S vs agent S games:\n",
    "ifiles_SS = ['TrainingData/games_played_SS_16022021162932.csv',\n",
    "             'TrainingData/games_played_SS_17022021002609.csv',\n",
    "             'TrainingData/games_played_SS_17022021075317.csv',\n",
    "             'TrainingData/games_played_SS_17022021091704.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-visibility",
   "metadata": {},
   "source": [
    "## Imports and initiate variables\n",
    "The imports and some variables used in the notebook is defined in the cell below.  Note that all the actual Tic Tac Toe gameplay code is in the script <strong>ttt.py</strong>.  Some unit testing was also included and can be run by excecuting <strong>pytest</strong> form the console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "controlled-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import ttt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "from datetime import date \n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "# remember to add sklearn\n",
    "\n",
    "# set some notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# default arrays\n",
    "# x columns\n",
    "x_columns = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18']\n",
    "\n",
    "# y columns\n",
    "y_columns = ['y1','y2','y3','y4','y5','y6','y7','y8','y9']\n",
    "\n",
    "# game_number and xy columns\n",
    "xy_columns = ['gameNr',\n",
    "             'x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18',\n",
    "             'y1','y2','y3','y4','y5','y6','y7','y8','y9']\n",
    "\n",
    "# df_columns used to moves history\n",
    "df_columns = ['gameNr', 'winner', 'xPlayer', 'oPlayer',\n",
    "              's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9',\n",
    "              'nextPlayer', 'nextMove',\n",
    "              'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
    "              'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18',\n",
    "              'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9']\n",
    "\n",
    "game_overview_columns = ['gameNr', 'winner', 'xPlayer', 'oPlayer',\n",
    "                         's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 'nextPlayer', 'nextMove']\n",
    "\n",
    "# create a dataframe that will contain all training stats\n",
    "df_training_stats = ttt.create_df_training_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-edgar",
   "metadata": {},
   "source": [
    "## Functions\n",
    "The following cell contains the functions used in this notebook. Again, please note that the gameplay functions are in ttt.py.\n",
    "\n",
    "<strong>play_games_and_output_file</strong><br>\n",
    "This function allows the play of of Tic Tac Toe.  This can be a human playing against an AI Agent, or AI agents playing against themselfs. The results of the game, together with the moves played are save in a CSV file.  The function returns the file name as output. \n",
    "\n",
    "<strong>improve_moves</strong><br>\n",
    "This function takes the game results and identifies the last move of the game that lead to a loss and then reverse the move.  The output is a dataframe containing moves that needs to be improved.  This will form part of the training data.\n",
    "\n",
    "<strong>dataframe_to_files_for_training</strong><br>\n",
    "This function write a training dataframe to two files ready for training, a feature file X and a labels file Y.\n",
    "\n",
    "<strong>train_the_model_from_file</strong><br>\n",
    "This function trains the model by using a file containing the features (boardstate) and another file containing the labels (move) and save the model as a jason and h5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesser-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions used in notebook\n",
    "def play_games_and_output_file(inr_of_games, inr_of_files, player_1, player_2, i_print_board, i_p_progress=True, mul=1):\n",
    "    \"\"\"\n",
    "    This function takes the game results and identifies the last move of the game that lead to a loss and\n",
    "    then reverse the move.  The output is a dataframe containing moves that needs to be improved.\n",
    "    This will form part of the training data.\n",
    "    \n",
    "    parameters: inr_of_game (int) number of games\n",
    "                inr_of_files (int) number of files in which the games will be split up\n",
    "                player_1 (char1) player x type, U for untrained, S for trained and L for trained further\n",
    "                player_2 (char1) player o type, U for untrained, S for trained and L for trained further\n",
    "                i_print_board (boolean) True if the board state should be printed\n",
    "    return: filename (string) name of file that was created        \n",
    "    \"\"\"\n",
    "    \n",
    "    # note, this function can be run multiple times in order to create files ready for training\n",
    "    ifiles = []\n",
    "    game_nr = 0\n",
    "    point = '' \n",
    "\n",
    "    # play the game nrOfGames times\n",
    "    total_nr_of_games = inr_of_files * inr_of_games * 2\n",
    "\n",
    "    # load Agent Smit\n",
    "    loaded_modelS = ttt.load_model('S')\n",
    "    loaded_modelS.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "\n",
    "\n",
    "    # load Agent Linki\n",
    "    loaded_modelL = ttt.load_model('L')    \n",
    "    loaded_modelL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])       \n",
    "    \n",
    "    for ifile_nr in range(inr_of_files):\n",
    "        \n",
    "        # create empty dataframes\n",
    "        df_all_played_games = ttt.create_df_all_played_games()\n",
    "\n",
    "        # create empty numpy\n",
    "        np_all_played_games = df_all_played_games.to_numpy()\n",
    "\n",
    "        # play the game nrOfGames times\n",
    "        for igame in range(inr_of_games):\n",
    "            \n",
    "            #------------------------------------------------------------------\n",
    "            # play the game of TTT with player 1 as X and player 2 as O\n",
    "            game_nr = game_nr + 1\n",
    "\n",
    "            # key for game\n",
    "            today = date.today()\n",
    "            current_date = today.strftime(\"%d%m%Y\")\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H%M%S\")        \n",
    "            i_game_nr = str(current_date) + str(current_time) + str(game_nr)\n",
    "            i_game_nr = int(i_game_nr)\n",
    "\n",
    "            # play the game of TTT with player 1 as X and player 2 as O\n",
    "            np_played_games = ttt.play_game(player_1, player_2, i_game_nr, i_print_board,\n",
    "                                            loaded_modelS, loaded_modelL).to_numpy()\n",
    "            np_all_played_games = np.vstack((np_all_played_games, np_played_games))\n",
    "            \n",
    "            #------------------------------------------------------------------          \n",
    "            # play the game of TTT with player 2 as X and player 1 as O\n",
    "            game_nr = game_nr + 1\n",
    "            \n",
    "            # key for game\n",
    "            today = date.today()\n",
    "            current_date = today.strftime(\"%d%m%Y\")\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H%M%S\")        \n",
    "            i_game_nr = str(current_date) + str(current_time) + str(game_nr)\n",
    "            i_game_nr = int(i_game_nr)            \n",
    "            \n",
    "            np_played_games = ttt.play_game(player_2, player_1, i_game_nr, i_print_board,\n",
    "                                            loaded_modelS, loaded_modelL).to_numpy()\n",
    "            np_all_played_games = np.vstack((np_all_played_games, np_played_games))        \n",
    "            ### \n",
    "            \n",
    "            #------------------------------------------------------------------                      \n",
    "            # print how may games have been played\n",
    "            if i_p_progress == True:\n",
    "                ttt.print_progress(total_nr_of_games, game_nr, 20, 'games played...')\n",
    "            else:\n",
    "                if point == '.':\n",
    "                    print('.', end='')\n",
    "                    point = ''\n",
    "                else:\n",
    "                    point = '.'\n",
    "\n",
    "        # save the games into a dataframe\n",
    "        df_all_played_games = pd.DataFrame(data=np_all_played_games, columns=df_columns)    \n",
    "\n",
    "        filename = 'TrainingData/games_played_' + player_1 + player_2 + '_' + str(ifile_nr) + '.csv'\n",
    "        df_all_played_games.to_csv(filename, index = False, header=True)    \n",
    "        ifiles.append(filename)\n",
    "        \n",
    "    # read games from files generated and consolidate into one file\n",
    "    df_all_played_games = ttt.create_df_all_played_games()\n",
    "    for ifile_name in ifiles:\n",
    "        df_all_played_games = df_all_played_games.append(pd.read_csv(ifile_name))\n",
    "\n",
    "    # mul\n",
    "    imulcounter = 0\n",
    "    while imulcounter <= mul:\n",
    "        df_all_played_games = df_all_played_games.append(df_all_played_games)\n",
    "        imulcounter = imulcounter + 1\n",
    "\n",
    "        \n",
    "    # create one file from the smaller files\n",
    "    today = date.today()\n",
    "    current_date = today.strftime(\"%d%m%Y\")\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H%M%S\")\n",
    "\n",
    "    filename = 'TrainingData/games_played_' + player_1 + player_2 + '_' + current_date + current_time + '.csv'\n",
    "    df_all_played_games.to_csv(filename, index = False, header=True)      \n",
    "\n",
    "    # remove the files that were created\n",
    "    for ifile_name in ifiles:\n",
    "        os.remove(ifile_name)\n",
    "    print('.')        \n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def improve_moves(df_all_played_games_int):\n",
    "    \"\"\"\n",
    "    This function takes the game results and identifies the moves that lead to a loss and then reverse the move\n",
    "    parameters: df_all_played_games_int (dataframe) Dataframe containing the games and the moves\n",
    "    return: df_improve_moves (dataframe) dataframe containing the moves that were reversed.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create a dataframe to contain all moves to improve.  \n",
    "    # These are moves that ead to a loss and replace it with the move of the opposite player\n",
    "\n",
    "    # create blank dataframe\n",
    "    df_improve_moves = pd.DataFrame(columns=df_columns, data=[])\n",
    "\n",
    "    # set improved moves to all moves that did not lead to a draw\n",
    "    df_improve_moves = df_improve_moves.append(df_all_played_games_int[df_all_played_games_int['winner'] != '-'])\n",
    "\n",
    "    # replace the played move with the player that won's move (therefore block it) \n",
    "    df_improve_moves[y_columns] = df_improve_moves[y_columns].shift(-1)\n",
    "\n",
    "    # filter to only include the moves that should be improved\n",
    "    df_improve_moves = df_improve_moves[(df_improve_moves['winner'] != df_improve_moves['nextPlayer'])]\n",
    "#     df_improve_moves = df_improve_moves[df_improve_moves['winner'] == df_improve_moves['nextPlayer']]\n",
    "\n",
    "    # # remove the first entries as using this to improve adds no value\n",
    "    df_improve_moves = df_improve_moves[df_improve_moves[x_columns].sum(axis=1) > 1]\n",
    "\n",
    "    # only take last moves, append twice to add importance\n",
    "    df_improve_moves = df_improve_moves.append(df_improve_moves.groupby('gameNr').tail(1))\n",
    "    df_improve_moves = df_improve_moves.append(df_improve_moves.groupby('gameNr').tail(1))\n",
    "    \n",
    "    # reset the index\n",
    "    df_improve_moves = df_improve_moves.reset_index(drop=True)\n",
    "    df_improve_moves = df_improve_moves.dropna()\n",
    "    return df_improve_moves\n",
    "\n",
    "\n",
    "def dataframe_to_files_for_training(player_1, player_2, total_nr_of_games):\n",
    "    \"\"\"\n",
    "    Write dataframe to files ready for training, a feature file X and a labels file Y.\n",
    "    parameters: player_1 (char1) player x type, U for untrained, S for trained and L for trained further\n",
    "                player_2 (char1) player x type, U for untrained, S for trained and L for trained further\n",
    "                total_nr_of_games (int) The total number of games played\n",
    "    return: df_improve_moves (dataframe) dataframe containing the moves that were reversed \n",
    "    \"\"\"    \n",
    "\n",
    "    # set file name parameters\n",
    "    gameMode = player_1 + player_2\n",
    "    nr_of_games_text = str(total_nr_of_games)\n",
    "\n",
    "    # create empty array for X (features) and Y (labels)\n",
    "    iX = np.zeros((len(df_training_final), 18), dtype=int)\n",
    "    iY = np.zeros((len(df_training_final), 9), dtype=int)\n",
    "\n",
    "    # convert dataframe to numpy arrays\n",
    "    iX = df_training_final[x_columns].to_numpy()\n",
    "    iY = df_training_final[y_columns].to_numpy()\n",
    "\n",
    "    # save file X\n",
    "    print('       - Save X...', end=' ')\n",
    "    filename_x = 'TrainingData/iX_' + gameMode + '_' + nr_of_games_text +  '_' + '.csv'\n",
    "    np.savetxt(filename_x, iX, delimiter=' ', fmt='%d')\n",
    "    print(filename_x, 'created')\n",
    "\n",
    "    # save file Y\n",
    "    print('       - Save y...', end=' ')\n",
    "    filename_y = 'TrainingData/iY_' + gameMode +  '_' + nr_of_games_text +  '_' + '.csv'\n",
    "    np.savetxt(filename_y, iY, delimiter=' ', fmt='%d')\n",
    "    print(filename_y, 'created')\n",
    "    \n",
    "    return filename_x, filename_y\n",
    "\n",
    "\n",
    "def train_the_model_from_file(filename_x, filename_y, imodel, iagent, i_verbose=1, batchsize=100):\n",
    "    \"\"\"\n",
    "    Train the model by using a file containing the features (boardstate) and another file containing\n",
    "    the labels (move) and save the model as a jason and h5 file. \n",
    "    \n",
    "    parameters: filename_x (string) file name of the file containing features\n",
    "                filename_y (string) file name of the file containing the labels\n",
    "                imodel (keras.models)\n",
    "                iagent (char1) indicates what to save the model as, is it agent S or agent L\n",
    "    return: history history of training\n",
    "            i_training_accuracy (int) training accuracy\n",
    "    \"\"\"    \n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Train Agent 1 on data that was generated by selfplay of two untrained agents playing against each other \n",
    "    inputFileX = filename_x\n",
    "    inputFileY = filename_y\n",
    "\n",
    "    # Traing model\n",
    "    if i_verbose != 0:\n",
    "        print('       - Load data to train AI agent...')\n",
    "\n",
    "    # read the X file into X_train\n",
    "    X = np.loadtxt(inputFileX, dtype='int')\n",
    "    if i_verbose != 0:\n",
    "        print('       - ', X.shape)\n",
    "\n",
    "    # read the Y file into y_train\n",
    "    y = np.loadtxt(inputFileY, dtype='int')\n",
    "    if i_verbose != 0:\n",
    "        print('       - ', y.shape)\n",
    "\n",
    "    # more than one record to train on    \n",
    "    if len(y) > 0:    \n",
    "        \n",
    "        # do train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "        # Fit model on training data\n",
    "        #imodel.fit(X_train, y_train, batch_size=100, verbose=1)  \"note verbose is output status\"\n",
    "        history = imodel.fit(X_train, y_train, validation_split=0.10, batch_size=batchsize, epochs=10, verbose=i_verbose)\n",
    "    #     history = model.fit(X_train, y_train, validation_split=0.10, batch_size=10, epochs=2, verbose=i_verbose)\n",
    "\n",
    "        # evaluate the model\n",
    "        score = imodel.evaluate(X_test, y_test, verbose=0)   \n",
    "        i_training_accuracy = score[1]\n",
    "\n",
    "        # set the training model names for saving the trained model\n",
    "        if iagent == 'L':\n",
    "            imodeljson = 'modelAgentLinki.json'\n",
    "            imodelh5 = 'modelAgentLinki.h5'\n",
    "        else:  \n",
    "            imodeljson = 'modelAgentSmit.json'\n",
    "            imodelh5 = 'modelAgentSmit.h5'    \n",
    "\n",
    "\n",
    "        # save the training model to a file\n",
    "        model_json = imodel.to_json()\n",
    "        with open(imodeljson, \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        imodel.save_weights(imodelh5)\n",
    "        if i_verbose != 0:\n",
    "            print('       - , Saved model to disk (' + imodelh5 + ')')\n",
    "    \n",
    "    return history, i_training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-fraud",
   "metadata": {},
   "source": [
    "## 1. Understanding the concept and exploring the data <a id='_1'></a>\n",
    "The concept that will be applied in this notebook came from looking at image recognition. On a conceptual level, we would like the AI agent to see the Tic Tac Toe board and then observes what move is made by the player.  The move that was made can be made by the actual AI agent, or by other players. Much the same as a human playing Tic Tac Toe and learning by doing, or observing how someone else plays.  The difficulty is, no one is explaining the rules of Tic Tac Toe to the AI agent, it will learn by looking at the board, then seeing what moves were made and after the game check which moves lead to a win. It is learning by doing or observing. It would be relatively trivial writing a rule based Agent to play Tic Tac Toe, however the approach followed here is to let an Agent teach itself how to play it.  \n",
    "\n",
    "<img src=\"overview.png\">\n",
    "\n",
    "First let's generate some data by letting an untrained agent play against and another untrained agent. To do this the <strong>play_games_and_output_file</strong> is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "signal-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - 2 / 2 games played... 21:04:32\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# the untrained agent plays against itself\n",
    "ifile_explore = play_games_and_output_file(1, 1, 'U', 'U', False)\n",
    "\n",
    "# read the file into a dataframe\n",
    "df_all_played_games = ttt.create_df_all_played_games()\n",
    "df_all_played_games = df_all_played_games.append(pd.read_csv(ifile_explore))\n",
    "try:\n",
    "    os.remove(ifile_explore)\n",
    "except:\n",
    "    file_removed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-greek",
   "metadata": {},
   "source": [
    "The *df_all_played_games* dataframe contains details on the games that were played. The data includes:\n",
    "the game number and who the winner is (player X or O). It also indicates who was player X and Player O.  In this example it is 'U', which is an untrained agent playing as 'X' and another untrained agent playing as 'O'.  The dataframe also contains the board state, if for example S1 = 'O', then the first position of the board was set to 'O'.  The data also contains who the player is that is making the next move and then the actual move.  Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "english-efficiency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            gameNr winner xPlayer oPlayer s1 s2 s3 s4 s5 s6 s7 s8 s9  \\\n0  180220212104321      -       U       U                              \n1  180220212104321      -       U       U        X                     \n2  180220212104321      -       U       U        X           O         \n3  180220212104321      -       U       U     X  X           O         \n4  180220212104321      -       U       U     X  X     O     O         \n\n  nextPlayer nextMove  \n0          X        3  \n1          O        7  \n2          X        2  \n3          O        5  \n4          X        4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameNr</th>\n      <th>winner</th>\n      <th>xPlayer</th>\n      <th>oPlayer</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>s6</th>\n      <th>s7</th>\n      <th>s8</th>\n      <th>s9</th>\n      <th>nextPlayer</th>\n      <th>nextMove</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>180220212104321</td>\n      <td>-</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>180220212104321</td>\n      <td>-</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180220212104321</td>\n      <td>-</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>180220212104321</td>\n      <td>-</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td>X</td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180220212104321</td>\n      <td>-</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td>X</td>\n      <td>X</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_played_games[game_overview_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "norwegian-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | |X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "\n",
      "The board above translates to positions S1 to S9: [' ' ' ' 'X' ' ' ' ' ' ' ' ' ' ' ' '] .\n",
      "Based on this board, the player O played move 7 :\n",
      "\n",
      " | |X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      "O| | \n",
      "\n",
      "The board above translates to positions S1 to S9: [' ' ' ' 'X' ' ' ' ' ' ' 'O' ' ' ' '] .\n",
      "Based on this board, the player X played move 2 :\n",
      "\n",
      " |X|X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      "O| | \n",
      "\n",
      "The board above translates to positions S1 to S9: [' ' 'X' 'X' ' ' ' ' ' ' 'O' ' ' ' '] .\n",
      "Based on this board, the player O played move 5 :\n",
      "\n",
      " |X|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "O| | \n",
      "\n",
      "The board above translates to positions S1 to S9: [' ' 'X' 'X' ' ' 'O' ' ' 'O' ' ' ' '] .\n"
     ]
    }
   ],
   "source": [
    "# output \n",
    "example_iindex = 1\n",
    "while example_iindex <= 4:\n",
    "    \n",
    "    i_demo_board = df_all_played_games.iloc[example_iindex][['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9']].values\n",
    "    game_board = ttt.output_board(i_demo_board, False)\n",
    "    print(game_board[0])\n",
    "    print(game_board[1])\n",
    "    print(game_board[2])\n",
    "    print(game_board[3])\n",
    "    print(game_board[4])\n",
    "    \n",
    "    print('\\nThe board above translates to positions S1 to S9:', i_demo_board, '.')\n",
    "    i_demo_move = df_all_played_games.iloc[example_iindex][['nextMove']].values[0]\n",
    "    i_demo_player = df_all_played_games.iloc[example_iindex][['nextPlayer']].values[0]\n",
    "    if example_iindex < 4:\n",
    "        print('Based on this board, the player', i_demo_player, 'played move',  i_demo_move, ':')\n",
    "        print('')\n",
    "    \n",
    "    example_iindex = example_iindex + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-plate",
   "metadata": {},
   "source": [
    "In order for the AI agent (the neural network) to understand the game state, the board and the moves must be reformatted (One-Hot Encoding).  This was already done in <strong>ttt.play_game</strong> and the <strong>df_all_played_games</strong> dataframe already contains this format. The x columns contains the boardstate and the y columns contains the move played. \n",
    "\n",
    "The x1 to x9 columns represent the 9 boards positions and contains a 1 if the position is filled by a 'X' and a 0 if it is not filled by a 'X'. x10 to x18 represents the 9 boards positions and contains a 1 if the position is filled by a 'O' and a 0 if it is not filled by a 'O'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comfortable-hampton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  s1 s2 s3 s4 s5 s6 s7 s8 s9 x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14  \\\n0                             0  0  0  0  0  0  0  0  0   0   0   0   0   0   \n1        X                    0  0  1  0  0  0  0  0  0   0   0   0   0   0   \n2        X           O        0  0  1  0  0  0  0  0  0   0   0   0   0   0   \n3     X  X           O        0  1  1  0  0  0  0  0  0   0   0   0   0   0   \n4     X  X     O     O        0  1  1  0  0  0  0  0  0   0   0   0   0   1   \n\n  x15 x16 x17 x18  \n0   0   0   0   0  \n1   0   0   0   0  \n2   0   1   0   0  \n3   0   1   0   0  \n4   0   1   0   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>s6</th>\n      <th>s7</th>\n      <th>s8</th>\n      <th>s9</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>x10</th>\n      <th>x11</th>\n      <th>x12</th>\n      <th>x13</th>\n      <th>x14</th>\n      <th>x15</th>\n      <th>x16</th>\n      <th>x17</th>\n      <th>x18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>X</td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>X</td>\n      <td>X</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_played_games[['s1','s2','s3','s4','s5','s6','s7','s8','s9'] + x_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-scout",
   "metadata": {},
   "source": [
    "The y1 to y9 columns represent the move played:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "northern-shipping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  nextMove y1 y2 y3 y4 y5 y6 y7 y8 y9\n0        3  0  0  1  0  0  0  0  0  0\n1        7  0  0  0  0  0  0  1  0  0\n2        2  0  1  0  0  0  0  0  0  0\n3        5  0  0  0  0  1  0  0  0  0\n4        4  0  0  0  1  0  0  0  0  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nextMove</th>\n      <th>y1</th>\n      <th>y2</th>\n      <th>y3</th>\n      <th>y4</th>\n      <th>y5</th>\n      <th>y6</th>\n      <th>y7</th>\n      <th>y8</th>\n      <th>y9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_played_games[['nextMove'] + y_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-river",
   "metadata": {},
   "source": [
    "This is now in a format that is understandable to a neural network. The AI agent will look at all good moves.  What makes a good move, using a simplistic view a 'good' move is a move that lead to a win. The dataframe will therefore be filtered and only the moves that lead to a win will be included in the training. This is stored in <strong>df_training</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "scenic-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             gameNr winner xPlayer oPlayer s1 s2 s3 s4 s5 s6 s7 s8 s9  \\\n9   180220212104322      X       U       U                              \n11  180220212104322      X       U       U           X     O            \n13  180220212104322      X       U       U     O     X     O  X         \n15  180220212104322      X       U       U     O     X  X  O  X  O      \n25  180220212104322      X       U       U                              \n\n   nextPlayer nextMove x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16  \\\n9           X        4  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   \n11          X        7  0  0  0  1  0  0  0  0  0   0   0   0   0   0   1   0   \n13          X        5  0  0  0  1  0  0  1  0  0   0   1   0   0   0   1   0   \n15          X        3  0  0  0  1  1  0  1  0  0   0   1   0   0   0   1   0   \n25          X        4  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   \n\n   x17 x18 y1 y2 y3 y4 y5 y6 y7 y8 y9  \n9    0   0  0  0  0  1  0  0  0  0  0  \n11   0   0  0  0  0  0  0  0  1  0  0  \n13   0   0  0  0  0  0  1  0  0  0  0  \n15   1   0  0  0  1  0  0  0  0  0  0  \n25   0   0  0  0  0  1  0  0  0  0  0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameNr</th>\n      <th>winner</th>\n      <th>xPlayer</th>\n      <th>oPlayer</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>s6</th>\n      <th>s7</th>\n      <th>s8</th>\n      <th>s9</th>\n      <th>nextPlayer</th>\n      <th>nextMove</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>x10</th>\n      <th>x11</th>\n      <th>x12</th>\n      <th>x13</th>\n      <th>x14</th>\n      <th>x15</th>\n      <th>x16</th>\n      <th>x17</th>\n      <th>x18</th>\n      <th>y1</th>\n      <th>y2</th>\n      <th>y3</th>\n      <th>y4</th>\n      <th>y5</th>\n      <th>y6</th>\n      <th>y7</th>\n      <th>y8</th>\n      <th>y9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>180220212104322</td>\n      <td>X</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>180220212104322</td>\n      <td>X</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>180220212104322</td>\n      <td>X</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td>X</td>\n      <td></td>\n      <td>O</td>\n      <td>X</td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>180220212104322</td>\n      <td>X</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td>O</td>\n      <td></td>\n      <td>X</td>\n      <td>X</td>\n      <td>O</td>\n      <td>X</td>\n      <td>O</td>\n      <td></td>\n      <td>X</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>180220212104322</td>\n      <td>X</td>\n      <td>U</td>\n      <td>U</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>X</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = df_all_played_games[df_all_played_games['winner'] == df_all_played_games['nextPlayer']]\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-bosnia",
   "metadata": {},
   "source": [
    "This will only train the model on willing move, the winning moves needs to be penalise. The proposal is to take the last loosing move, which is a 'bad' move and reverse it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stupid-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            gameNr x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17  \\\n0  180220212104322  0  0  0  1  0  0  1  0  0   0   0   0   0   0   1   0   0   \n1  180220212104322  0  0  0  1  1  0  1  0  0   0   1   0   0   0   1   0   0   \n2  180220212104322  0  0  0  1  0  0  1  0  0   0   0   0   0   0   1   0   0   \n3  180220212104322  0  0  0  1  1  0  1  0  0   0   1   0   0   0   1   0   0   \n4  180220212104322  0  0  0  1  0  0  1  0  0   0   0   0   0   0   1   0   0   \n\n  x18 y1 y2 y3 y4 y5 y6 y7 y8 y9  \n0   0  0  0  0  0  1  0  0  0  0  \n1   0  0  0  1  0  0  0  0  0  0  \n2   0  0  0  0  0  1  0  0  0  0  \n3   0  0  0  1  0  0  0  0  0  0  \n4   0  0  0  0  0  1  0  0  0  0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameNr</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>x10</th>\n      <th>x11</th>\n      <th>x12</th>\n      <th>x13</th>\n      <th>x14</th>\n      <th>x15</th>\n      <th>x16</th>\n      <th>x17</th>\n      <th>x18</th>\n      <th>y1</th>\n      <th>y2</th>\n      <th>y3</th>\n      <th>y4</th>\n      <th>y5</th>\n      <th>y6</th>\n      <th>y7</th>\n      <th>y8</th>\n      <th>y9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>180220212104322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>180220212104322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180220212104322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>180220212104322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180220212104322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improve_moves = improve_moves(df_all_played_games)\n",
    "df_improve_moves[xy_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-testament",
   "metadata": {},
   "source": [
    "Lets look at one final example of the board state, the one-hot-encoding and the move to improve:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-portuguese",
   "metadata": {},
   "source": [
    "<img src=\"improvemoves.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-assumption",
   "metadata": {},
   "source": [
    "The next secion will train Agent S to play Tic Tac Toe. It involves creating training data, then training a neural network on the data and lastly evaluating the agent created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-disclaimer",
   "metadata": {},
   "source": [
    "## 2. Generate training data and train Agent S <a id='_2'></a>\n",
    "This section will train a neural network on game data that was generated by two untrained agents playing against itself. The output of this section will be a trained sequential neural network saved as Agent S (*modelAgentSmit.json* and *modelAgentSmit.h5*). \n",
    "### 2.1 Create training data<a id='_21'></a>\n",
    "Selfplay will be used in order to generate game data. The output is a file that can be used as the basis for training a neural net. \n",
    "#### 2.1.1 Create training data: Untrained Agent vs Untrained Agent\n",
    "This cell creates gameplay data by allowing two untrained agents to play against itself. It can be run multiple times to generate more gameplay data. In order to use this file in training, the filename must be added in the <strong>ifiles_UU</strong> array.  The file contains random moves played on a Tic Tac Toe board, the game moves are generated by making use of: *prednr = random.randint(1, 9)*. \n",
    "\n",
    "Untrained Agent (See *ttt.make_prediction_math(iboard, ynew)*):\n",
    "\n",
    "        move = random.randint(1, 9)\n",
    "        move_array = get_y(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-regulation",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - 1000 / 20000 games played... 21:04:37\n",
      "       - 2000 / 20000 games played... 21:04:41\n",
      "       - 3000 / 20000 games played... 21:04:44\n",
      "       - 4000 / 20000 games played... 21:04:49\n",
      "       - 5000 / 20000 games played... 21:04:53\n",
      "       - 6000 / 20000 games played... 21:04:58\n",
      "       - 7000 / 20000 games played... 21:05:03\n",
      "       - 8000 / 20000 games played... 21:05:07\n"
     ]
    }
   ],
   "source": [
    "if do_gen_ifile_UU is True:\n",
    "    # the untrained agent plays against itself\n",
    "    ifile_UU = play_games_and_output_file(100, 100, 'U', 'U', False)\n",
    "    print(ifile_UU)\n",
    "else:\n",
    "    print('Untrained Agent vs Untrained Agent skipped')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-atlas",
   "metadata": {},
   "source": [
    "### 2.2 Train Agent S<a id='_22'></a>\n",
    "#### 2.2.1 Train Agent S: Create neural network\n",
    "This creates a Keras sequential neural network and saves it as *modelAgentSmit.json* and *modelAgentSmit.h5*.\n",
    "\n",
    "Note that the input shape is 18 which is equal to the number of X columns. The output layer has a shape of 9, which is the same as the y columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-polish",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # remove the model \n",
    "    try:\n",
    "        os.remove('modelAgentSmit.json')\n",
    "    except:\n",
    "        file_removed = True\n",
    "\n",
    "    try:\n",
    "        os.remove('modelAgentSmit.h5')\n",
    "    except:\n",
    "        file_removed = True    \n",
    "\n",
    "    # Create Neural Net \n",
    "    modelS = Sequential()\n",
    "    modelS.add(Dense(18, activation='relu', input_shape=(18,)))\n",
    "    modelS.add(Dense(24, activation='relu'))          # Add one hidden layer    \n",
    "    modelS.add(Dense(18, activation='relu'))          # Add one hidden layer        \n",
    "    modelS.add(Dense(12, activation='relu'))          # Add one hidden layer\n",
    "    modelS.add(Dense(12, activation='relu'))          # Add one hidden layer\n",
    "    modelS.add(Dense(9, activation='softmax'))        # Add an output layer     //\n",
    "    modelS.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # set the training model names for saving the trained model\n",
    "    imodeljson = 'modelAgentSmit.json'\n",
    "    imodelh5 = 'modelAgentSmit.h5'    \n",
    "\n",
    "    # save the training model to a file\n",
    "    model_json = modelS.to_json()\n",
    "    with open(imodeljson, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    modelS.save_weights(imodelh5)\n",
    "\n",
    "else:\n",
    "    modelS = ttt.load_model('S')\n",
    "    modelS.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "\n",
    "modelS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-cincinnati",
   "metadata": {},
   "source": [
    "<strong>Evaluate untrained agent's ability to play Tic Tac Toe</strong><br>\n",
    "As a benchmark, the untrained agent will first play against random moves in order to determine how good an untraind agent is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-seventh",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # the untrained agent plays 50 games as X and then 50 games as O\n",
    "    ifile = play_games_and_output_file(50, 1, 'U', 'S', False)\n",
    "\n",
    "    # read all files in list and save in dataframe df_all_played_games\n",
    "    df_all_played_games = ttt.create_df_all_played_games()\n",
    "    df_all_played_games = df_all_played_games.append(pd.read_csv(ifile))\n",
    "    os.remove(ifile)\n",
    "    df_all_played_games = df_all_played_games.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-casino",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # plot game results\n",
    "    df_training_stats = ttt.get_training_stats(df_all_played_games, df_training_stats, 0)\n",
    "\n",
    "    x = np.arange(2)\n",
    "    wins_list = df_training_stats.loc[0][['U_wins', 'S_wins']].to_list()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # ax.yaxis.set_major_formatter(formatter)\n",
    "    plt.bar(x, wins_list)\n",
    "    plt.xticks(x, ('Random', 'Agent S' ))\n",
    "    \n",
    "    # displaying the title \n",
    "    plt.title('Untrained Agent S vs Random play')\n",
    "    plt.show()\n",
    "\n",
    "    print('% U wins:', wins_list[0] / (wins_list[0] + wins_list[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-ballot",
   "metadata": {},
   "source": [
    "#### 2.2.2 Train Agent S: Load training data and train model\n",
    "Train the neural network on the training data in *ifiles_UU* (Untrained Agent vs Untrained Agent).  <br>\n",
    "Steps:\n",
    "- Step 1: Get all the relevant gameplay data form the *ifiles_UU* list and save it in df_all_played_games.\n",
    "- Step 2: Only include the winning moves and the moves to improve and append it into df_training_final.\n",
    "- Step 3: From df_training_final create create a features file (X) and a labels file(y). \n",
    "- Step 4: Train the model (outcome is Agent S)\n",
    "- Step 5: Evaluate the model by looking at the training accuracy and the gameplay of the trained agent vs an untrained agent (100 games)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-father",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # train Agent S on U vs U data\n",
    "    player_1 = 'U'\n",
    "    player_2 = 'U'\n",
    "    train_model_ind = 'S'\n",
    "    training_files = ifiles_UU\n",
    "    \n",
    "    # train agent on already played data\n",
    "    if len(training_files) > 0:                                                \n",
    "        print('Play, Clean, Train', player_1, player_2)\n",
    "\n",
    "        print('--- 1: Play ') \n",
    "        df_all_played_games = ttt.create_df_all_played_games()\n",
    "\n",
    "        # Step 1: add training data from files generated\n",
    "        for training_file in training_files:                                         \n",
    "            print('       - File uploaded to dataframe: ', training_file) \n",
    "            df_all_played_games = df_all_played_games.append(pd.read_csv(training_file)) \n",
    "\n",
    "        print('--- 2: Clean ')   \n",
    "        print('       - Winning moves... ') \n",
    "        # Step: 2.1 Get all the moves that leads to a win\n",
    "        df_training = df_all_played_games[df_all_played_games['winner'] == df_all_played_games['nextPlayer']]\n",
    "        df_training = df_training.reset_index(drop=True)\n",
    "\n",
    "        print('       - Moves to improve... ')     \n",
    "        # Step 2.2: Get moves to improve\n",
    "        # call funtion to get moves that were improved because the game playes lead to a loss\n",
    "        df_improve_moves = improve_moves(df_all_played_games)\n",
    "\n",
    "        # Step 2.3: Prepare data on which training will be based\n",
    "        df_training_final = ttt.create_df_all_played_games()\n",
    "        df_training_final = df_training_final.append(df_training)\n",
    "        df_training_final = df_training_final.append(df_improve_moves)\n",
    "        df_training_final = df_training_final.dropna()\n",
    "\n",
    "        print('       - Create X and Y... ')        \n",
    "        # Step 3 prepare x and y\n",
    "        filename_x, filename_y = dataframe_to_files_for_training(player_1, player_2, 1)    \n",
    "\n",
    "        # Step 4 train model\n",
    "        print('--- 3: Train ')        \n",
    "        history, i_training_accuracy = train_the_model_from_file(filename_x, filename_y, modelS, train_model_ind, i_verbose=1, batchsize=100)\n",
    "        print('       - Accuracy: ', i_training_accuracy) \n",
    "        print('')\n",
    "\n",
    "        print('--- 4: Evaluate model S by use of selfplay ')        \n",
    "        \n",
    "        # Step 5 evaluate gameplay\n",
    "        if train_model_ind == 'S':\n",
    "            modelS = ttt.load_model(train_model_ind)\n",
    "            modelS.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "        else:\n",
    "            modelL = ttt.load_model(train_model_ind)\n",
    "            modelL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "\n",
    "        # the untrained agent plays 50 games as X and then 50 games as O\n",
    "        ifile_evaluate = play_games_and_output_file(50, 1, 'U', train_model_ind, False)\n",
    "        # read all files in list and save in dataframe df_all_played_games\n",
    "        df_all_played_games = ttt.create_df_all_played_games()\n",
    "        df_all_played_games = df_all_played_games.append(pd.read_csv(ifile_evaluate))\n",
    "        os.remove(ifile_evaluate)\n",
    "        df_all_played_games = df_all_played_games.dropna()\n",
    "\n",
    "        # plot game results\n",
    "        df_training_stats = ttt.get_training_stats(df_all_played_games, df_training_stats, 1)      #1 = US\n",
    "        wins_list = df_training_stats.loc[1][['U_wins', 'S_wins']].to_list()\n",
    "\n",
    "        x = np.arange(2)\n",
    "        wins_list = df_training_stats.loc[1][['U_wins', 'S_wins']].to_list()\n",
    "        print('       - U Wins: ', wins_list[0], ' | S Wins: ', wins_list[1])\n",
    "        print('       - % U wins:', wins_list[0] / (wins_list[0] + wins_list[1]))                                 \n",
    "        print('       - Training file created: ', ifile)\n",
    "        print('')      \n",
    "    else:\n",
    "        print('No file found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-chair",
   "metadata": {},
   "source": [
    "### 2.3 Agent S evaluation and conclusion<a id='_23'></a>\n",
    "From the outcome it is clear that the trained agent (Agent S) is much beter than a untrained agent in paying Tic Tac Toe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-panic",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-engagement",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelS == True:\n",
    "    # plot game results\n",
    "    df_training_stats = ttt.get_training_stats(df_all_played_games, df_training_stats, 1)\n",
    "\n",
    "    x = np.arange(2)\n",
    "    wins_list = df_training_stats.loc[1][['U_wins', 'S_wins']].to_list()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # ax.yaxis.set_major_formatter(formatter)\n",
    "    plt.bar(x, wins_list)\n",
    "    plt.xticks(x, ('Random', 'Agent S'))\n",
    "    plt.title('Agent S vs Random play')    \n",
    "    plt.show()\n",
    "    print('% U wins:', wins_list[0] / (wins_list[0] + wins_list[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-joint",
   "metadata": {},
   "source": [
    "The next section will improve on Agent S and create a new AI Agent called Agent L."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-sunday",
   "metadata": {},
   "source": [
    "## 3. Generate training data and train Agent L (improvement on Agent S)<a id='_3'></a>\n",
    "This section will train a neural net on game data that was generated by multiple type of gameplay. \n",
    "First it will generate data based on Agent S playing an untrained agent (3.1.1). Next it will generate data based on gameplay of Agent S against Agent S (3.1.2) and lastly it will generate test data of a Human playing against Agent S (3.1.3).  The output of this section will be a trained sequential neural net saved as Agent S (*modelAgentLinki.json* and *modelAgentLinki.h5*). \n",
    "### 3.1 Create training data<a id='_31'></a>\n",
    "Selfplay will be used in order to generate game data. The output is a file that can be used as the basis for training a neural net. These cells create gameplay data by allowing an untrained agent to play against Agent S, Agent S playing against Agent S and Agent S playing Against a Human. It can be run multiple times to generate more gameplay data. \n",
    "\n",
    "#### 3.1.1 Create training data: Untrained Agent vs Agent S\n",
    "\n",
    "Untrained Agent vs Agent S generates a file containing plays by the untrained agent based on random moves and Agent Sbased on the neural network output.  In order to use this file in training, the filename must be added in the *ifiles_US* array.\n",
    "\n",
    "Untrained Agent (see *ttt.make_prediction_math(iboard, ynew)*):\n",
    "\n",
    "        move = random.randint(1, 9)\n",
    "        move_array = get_y(move)\n",
    "\n",
    "Agent S (see in *make_prediction(curr_board, player, loaded_modelS, loaded_modelL)*):\n",
    "\n",
    "        ynew = loaded_modelS.predict_proba(iX)        \n",
    "        ynew[0] = ynew[0] ** gamma / np.sum(ynew[0] ** gamma)\n",
    "        ynew[0] = np.around(ynew[0].astype(float), decimals=3)\n",
    "        ynew[0] /= ynew[0].sum()\n",
    "        ynew[0] = ynew[0] * irandomness        # allow some randomness\n",
    "        out_ynew = np.random.multinomial(1, ynew[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-contemporary",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_gen_ifile_US is True:\n",
    "    # create game data from gameplay of untrained agent against Agent S\n",
    "    ifile_US = play_games_and_output_file(1000, 10, 'U', 'S', False)\n",
    "    print(ifile_US)\n",
    "else:\n",
    "    print('Untrained Agent vs Agent S skipped')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-leave",
   "metadata": {},
   "source": [
    "#### 3.1.2 Create training data: Agent S vs Agent S\n",
    "Agent S vs Agent S generates a file containing gameplays by Agent S against Agent S.  In order to use this file in training, the filename must be added in the *ifiles_SS* array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-howard",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_gen_ifile_SS is True:\n",
    "    # create game data from gameplay of Agent S vs against Agent S\n",
    "    ifile_SS = play_games_and_output_file(1000, 10, 'S', 'S', False)\n",
    "    print(ifile_SS)\n",
    "else:\n",
    "    print('Agent S vs Agent S skipped')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-experience",
   "metadata": {},
   "source": [
    "#### 3.1.3 Create training data: Agent S vs Human\n",
    "Agent S vs Human allows a human to play against Agent S and generates a file containing gameplays.  In order to use this file in training, the filename must be added in the *ifiles_SH* array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-processing",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_gen_ifile_SH is True:\n",
    "\n",
    "    df_concolidate = []\n",
    "    \n",
    "    # how many times to play against Agent S\n",
    "    total_nr_h_vs_s = 1\n",
    "    icount_h_vs_s = 0\n",
    "    created_play_files_SH = []\n",
    "    while icount_h_vs_s < total_nr_h_vs_s:\n",
    "        icount_h_vs_s = icount_h_vs_s + 1\n",
    "        ifile = play_games_and_output_file(1, 1, 'H', 'S', True, True, 10)\n",
    "        created_play_files_SH.append(ifile) \n",
    "\n",
    "    df_concolidate = ttt.create_df_all_played_games()\n",
    "           \n",
    "    # append all files created into one dataframe\n",
    "    for ifile_SH in created_play_files_SH:\n",
    "        df_concolidate = df_concolidate.append(pd.read_csv(ifile))\n",
    "\n",
    "    # clean up and delete files\n",
    "    created_play_files_SH = list(dict.fromkeys(created_play_files_SH))    \n",
    "    for ifile_SH in created_play_files_SH:  \n",
    "        try:\n",
    "            os.remove(ifile_SH)          \n",
    "            print('       - ', ifile_SH, ' removed')\n",
    "        except:\n",
    "            print('       - could not delete', ifile)        \n",
    "\n",
    "    ifile_SH = 'TrainingData/games_played_UH_all.csv'\n",
    "    print('       - Human training file created: ', ifile_SH)\n",
    "    df_concolidate.to_csv(ifile, index = False, header=True)     \n",
    "    df_concolidate = ttt.create_df_all_played_games()\n",
    "else:\n",
    "    print('Agent S vs Human skipped')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-verification",
   "metadata": {},
   "source": [
    "### 3.2 Train model L<a id='_32'></a>\n",
    "#### 3.2.1 Train Agent L: Create neural network\n",
    "This creates a Keras sequential neural network and saves it as *modelAgentLinki.json* and *modelAgentLinki.h5*.\n",
    "Note that the input shape is 18 which is equal to the number of X columns. The output layer has a shape of 9, which is the same as the y columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-royalty",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelL == True:\n",
    "    # remove the model \n",
    "    try:\n",
    "        os.remove('modelAgentLinki.json')\n",
    "    except:\n",
    "        file_removed = True\n",
    "\n",
    "    try:\n",
    "        os.remove('modelAgentLinki.h5')\n",
    "    except:\n",
    "        file_removed = True    \n",
    "\n",
    "    # Create Neural Net \n",
    "    modelL = Sequential()\n",
    "    modelL.add(Dense(18, activation='relu', input_shape=(18,)))\n",
    "    modelL.add(Dense(24, activation='relu'))          # Add one hidden layer    \n",
    "    modelL.add(Dense(18, activation='relu'))          # Add one hidden layer        \n",
    "    modelL.add(Dense(12, activation='relu'))          # Add one hidden layer\n",
    "    modelL.add(Dense(12, activation='relu'))          # Add one hidden layer\n",
    "    modelL.add(Dense(9, activation='softmax'))        # Add an output layer     //\n",
    "    modelL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # set the training model names for saving the trained model\n",
    "    imodeljson = 'modelAgentLinki.json'\n",
    "    imodelh5 = 'modelAgentLinki.h5'    \n",
    "\n",
    "    # save the training model to a file\n",
    "    model_json = modelL.to_json()\n",
    "    with open(imodeljson, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    modelL.save_weights(imodelh5)\n",
    "\n",
    "else:\n",
    "    modelL = ttt.load_model('L')\n",
    "    modelL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "\n",
    "modelL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-montana",
   "metadata": {},
   "source": [
    "#### 3.3.2 Train Agent L: Load training data and train model\n",
    "Train the neural network on the training data in *ifiles_UU*, *ifiles_US*, *ifiles_SS*, *ifiles_UH*.  <br>\n",
    "Steps:\n",
    "- Step 1: Get all the relevant gameplay data form the *ifiles_UU*, *ifiles_US*, *ifiles_SS*, *ifiles_UH* lists and save it in df_all_played_games.\n",
    "- Step 2: Only include the winning moves and the moves to improve and append it into df_training_final.\n",
    "- Step 3: From df_training_final create create a features file (X) and a labels file(y). \n",
    "- Step 4: Train the model (outcome is Agent L).\n",
    "- Step 5: Evaluate the model by looking at the training accuracy and the gameplay of the trained agent vs an untrained agent (100 games)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-contents",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelL == True:\n",
    "    # train Agent S on U vs U data\n",
    "    player_1 = 'U'\n",
    "    player_2 = 'L'\n",
    "    train_model_ind = 'L'\n",
    "    \n",
    "    training_files = ifiles_US + ifiles_SS + ifiles_UH \n",
    "   \n",
    "    # train agent on already played data\n",
    "    if len(training_files) > 0:                                                \n",
    "        print('Play, Clean, Train', player_1, player_2)\n",
    "\n",
    "        print('--- 1: Play ') \n",
    "        df_all_played_games = ttt.create_df_all_played_games()\n",
    "\n",
    "        # add training data from files generated\n",
    "        for training_file in training_files:                                         \n",
    "            print('       - File uploaded to dataframe: ', training_file) \n",
    "            df_all_played_games = df_all_played_games.append(pd.read_csv(training_file)) \n",
    "\n",
    "        print('--- 2: Clean ')   \n",
    "        print('       - Winning moves... ') \n",
    "        # Step: 2.1 Get all the moves that leads to a win\n",
    "        df_training = df_all_played_games[df_all_played_games['winner'] == df_all_played_games['nextPlayer']]\n",
    "        df_training = df_training.reset_index(drop=True)\n",
    "\n",
    "        print('       - Moves to improve... ')     \n",
    "        # Step 2.2: Get moves to improve\n",
    "        # call funtion to get moves that were improved because the game playes lead to a loss\n",
    "        df_improve_moves = improve_moves(df_all_played_games)\n",
    "\n",
    "        # Step 2.3: Prepare data on which training will be based\n",
    "        df_training_final = ttt.create_df_all_played_games()\n",
    "        df_training_final = df_training_final.append(df_training)\n",
    "        df_training_final = df_training_final.append(df_improve_moves)\n",
    "        df_training_final = df_training_final.dropna()\n",
    "\n",
    "        print('       - Create X and Y... ')        \n",
    "        # Step 3 prepare x and y\n",
    "        filename_x, filename_y = dataframe_to_files_for_training(player_1, player_2, 1)    \n",
    "\n",
    "        # Step 4 train model\n",
    "        print('--- 3: Train ')        \n",
    "        history, i_training_accuracy = train_the_model_from_file(filename_x, filename_y, modelL, train_model_ind, i_verbose=1, batchsize=400)\n",
    "        print('       - Accuracy: ', i_training_accuracy) \n",
    "        print('')\n",
    "\n",
    "        print('--- 4: Evaluate model L by use of selfplay ')        \n",
    "        \n",
    "        # Step 5 evaluate gameplay\n",
    "        if train_model_ind == 'S':\n",
    "            modelS = ttt.load_model(train_model_ind)\n",
    "            modelS.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "        else:\n",
    "            modelL = ttt.load_model(train_model_ind)\n",
    "            modelL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "\n",
    "        # the untrained agent plays 50 games as X and then 50 games as O\n",
    "        ifile_evaluate = play_games_and_output_file(50, 1, 'U', train_model_ind, False)\n",
    "        # read all files in list and save in dataframe df_all_played_games\n",
    "        df_all_played_games = ttt.create_df_all_played_games()\n",
    "        df_all_played_games = df_all_played_games.append(pd.read_csv(ifile_evaluate))\n",
    "        os.remove(ifile_evaluate)\n",
    "        df_all_played_games = df_all_played_games.dropna()\n",
    "\n",
    "        # plot game results\n",
    "        df_training_stats = ttt.get_training_stats(df_all_played_games, df_training_stats, 2)      #2 = UL\n",
    "        wins_list = df_training_stats.loc[2][['U_wins', 'S_wins', 'L_wins']].to_list()\n",
    "\n",
    "        x = np.arange(3)\n",
    "        wins_list = df_training_stats.loc[2][['U_wins', 'S_wins', 'L_wins']].to_list()\n",
    "        print('       - U Wins: ', wins_list[0], ' | S Wins: ', wins_list[1], ' | L Wins: ', wins_list[2])\n",
    "        print('       - % U wins:', wins_list[0] / (wins_list[0] + wins_list[1] + wins_list[2]))                                 \n",
    "        print('')      \n",
    "    else:\n",
    "        print('No file found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-harvey",
   "metadata": {},
   "source": [
    "### 3.3 Agent L evaluation and conclusion<a id='_33'></a>\n",
    "\n",
    "How did the model do in terms of training accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-southwest",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelL == True:\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-christianity",
   "metadata": {},
   "source": [
    "The accuracy of the model did increase, however it is not close to 90%, this canbe expected as there are a very high numer of different outcomes for a spesific board that will lead to a win.  The neural network should return the most likely play that will lead to a win. \n",
    "\n",
    "Lets look at a more pragmatic way to evaluate the agents ability to play Tic Tac Toe:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-helping",
   "metadata": {},
   "source": [
    "<strong>How did Agent S do against an untrained agent?</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-shopper",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelL == True:\n",
    "    # plot game results\n",
    "    df_training_stats = ttt.get_training_stats(df_all_played_games, df_training_stats, 2)\n",
    "\n",
    "    x = np.arange(3)\n",
    "    wins_list = df_training_stats.loc[2][['U_wins', 'S_wins', 'L_wins']].to_list()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # ax.yaxis.set_major_formatter(formatter)\n",
    "    plt.bar(x, wins_list)\n",
    "    plt.xticks(x, ('Random', 'Agent S', 'Agent L'))\n",
    "    plt.title('Agent L vs Random play')    \n",
    "    plt.show()\n",
    "    print('% U wins:', wins_list[0] / (wins_list[0] + wins_list[1] + wins_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-brown",
   "metadata": {},
   "source": [
    "<strong>Lets check in more detail...</strong><br>\n",
    "An untrained agent will play Tic Tac Toe against a Agent L. The untrained agent wins and trained agent wins are recorded.<br>\n",
    "\n",
    "<strong>Metric</strong><br>\n",
    "The data provided generated contains the untrained agent wins and trained agent wins. \n",
    "The metric used in order to determine which player is better at playing Tic Tac Toe.\n",
    "<br>\n",
    "\n",
    "<strong>Objective</strong><br>\n",
    "The objective is to check if the trained agent is signitifantly better at playing Tic Tac Toe than an untrained Agent. \n",
    "<br>\n",
    "\n",
    "<strong>Hypothesis</strong><br>\n",
    "H0: trained_agent_wins - unrained_agent_wins = 0 <br>\n",
    "H1: trained_agent_wins - unrained_agent_wins > 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-douglas",
   "metadata": {},
   "source": [
    "<strong>Steps: </strong>\n",
    "    \n",
    "1. Compute the <strong>observed difference</strong> between the metric, trained agent wins and untrained agent wins.<br>\n",
    "2. <strong>Simulate the sampling distribution</strong> for the difference in trained agent wins and untrained agent wins. This is done by making use of bootstrapping.<br>\n",
    "3. Used this sampling distribution to <strong>simulate the distribution under the null hypothesis</strong>, by creating a random normal distribution centered at 0 with the same spread and size.<br>\n",
    "4. Compute the p-value by finding the proportion of values in the null distribution that were greater than our observed difference.<br>\n",
    "5. Used this p-value to determine the statistical significance of our observed difference.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-roads",
   "metadata": {},
   "source": [
    "#### 3.3.0 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-thriller",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def label_U_win (row):\n",
    "    if row['xPlayer'] == 'U' and row['winner'] == 'X':\n",
    "        return 1\n",
    "    elif row['oPlayer'] == 'U' and row['winner'] == 'O':\n",
    "        return 1   \n",
    "    else:\n",
    "        return 0        \n",
    "    \n",
    "def label_L_win (row):\n",
    "    if row['xPlayer'] == 'L' and row['winner'] == 'X':\n",
    "        return 1\n",
    "    elif row['oPlayer'] == 'L' and row['winner'] == 'O':\n",
    "        return 1   \n",
    "    else:\n",
    "        return 0        \n",
    "\n",
    "if do_final_evaluL is True:\n",
    "    ifile_evaluate = play_games_and_output_file(500, 1, 'U', train_model_ind, False)\n",
    "    # read all files in list and save in dataframe df_all_played_games\n",
    "    df_all_played_games = ttt.create_df_all_played_games()\n",
    "    df_all_played_games = df_all_played_games.append(pd.read_csv(ifile_evaluate))\n",
    "    os.remove(ifile_evaluate)\n",
    "    df_all_played_games = df_all_played_games.dropna()\n",
    "    \n",
    "    # get all games\n",
    "    df_games = df_all_played_games.groupby('gameNr')\n",
    "    df_games = df_games.first()    \n",
    "       \n",
    "    df_games['U_win'] = df_games.apply (lambda row: label_U_win(row), axis=1)\n",
    "    df_games['L_win'] = df_games.apply (lambda row: label_L_win(row), axis=1)    \n",
    "        \n",
    "    # dataframe containing indicators.  1 indicates a win.  \n",
    "    df_games = pd.DataFrame({\"L_Win\":df_games['L_win'].tolist(), \n",
    "                            \"U_Win\":df_games['U_win'].tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-explanation",
   "metadata": {},
   "source": [
    "#### 3.3.1 Computed the observed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-swaziland",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_final_evaluL is True:\n",
    "    obs_diff = df_games['L_Win'].sum() - df_games['U_Win'].sum()\n",
    "    print(obs_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-stylus",
   "metadata": {},
   "source": [
    "#### 3.3.2 Simulate the sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-theme",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create sampling distribution of difference between number of wins by trained agent vs untrained agent\n",
    "if do_final_evaluL is True:\n",
    "    diffs = []\n",
    "    for _ in range(10000):\n",
    "        df_sample = df_games.sample(df_games.shape[0], replace = True)\n",
    "        sample_diff = df_sample['L_Win'].sum() - df_sample['U_Win'].sum()\n",
    "\n",
    "        diffs.append(sample_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-sugar",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "if do_final_evaluL is True:\n",
    "    diffs = np.array(diffs)\n",
    "    diffs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-valve",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plot sampling distribution\n",
    "if do_final_evaluL is True:\n",
    "    plt.hist(diffs);\n",
    "    plt.axvline(x=obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-bruce",
   "metadata": {},
   "source": [
    "#### 3.3.3 Simulate the distribution under the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-classics",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# simulate distribution under the null hypothesis\n",
    "if do_final_evaluL is True:\n",
    "    null_vals = np.random.normal(0, diffs.std(), diffs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-colors",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plot null distribution\n",
    "if do_final_evaluL is True:\n",
    "    plt.hist(null_vals);\n",
    "\n",
    "    # plot line for observed statistic\n",
    "    plt.axvline(x=obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-joyce",
   "metadata": {},
   "source": [
    "#### 3.3.4. Compute the p-value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-massachusetts",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# compute p value\n",
    "if do_final_evaluL is True:\n",
    "    p_value = (null_vals > obs_diff).mean()\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-appreciation",
   "metadata": {},
   "source": [
    "#### 3.3.5 Use p-value to determine the statistical significance of our observed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-qualification",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_final_evaluL is True:\n",
    "    if p_value < 0.01:\n",
    "        print('reject H0')\n",
    "    else:\n",
    "        print('fail to reject H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-indonesian",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enabling-frequency",
   "metadata": {},
   "source": [
    "## 4. Conclusion<a id='_4'></a>\n",
    "### 4.1 Evaluate AI agents<a id='_41'></a>\n",
    "Looking at the training accuracy, it seems like the model is not fitting that well.  However, it should be noted that there are a number of different ways to win a game of Tic Tac Toe and therefore it is very unlikely to get to a high training accuracy.  A move pragmatic way to look at the models effectiveness is to look at hos well it plays the game of Tic TAc Toe against the untrained agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-birmingham",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if do_train_modelL == True:\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-quarter",
   "metadata": {},
   "source": [
    "From below, it is clear the the models ability to play Tic Tac Toe imrproved through the training cycles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-fraction",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "u_wins = df_training_stats['U_wins'].to_list()\n",
    "s_wins = df_training_stats['S_wins'].to_list()\n",
    "l_wins = df_training_stats['L_wins'].to_list()\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = u_wins\n",
    "bars2 = s_wins\n",
    "bars3 = l_wins\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1,  width=barWidth, edgecolor='white', label='Untrained Agent') #var1\n",
    "plt.bar(r2, bars2,  width=barWidth, edgecolor='white', label='Agent S') #var2\n",
    "plt.bar(r3, bars3,  width=barWidth, edgecolor='white', label='Agent L') #var3\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Wins by agent', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['before training', 'After training Agent S', 'After training Agent L'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-particle",
   "metadata": {},
   "source": [
    "Out of the test done in 3.3, it is also confirmed that the <strong>H0</strong> hypothesis is rejected at a 0.01% level of significance.  Therefore it can be accepted that Agent L is better at laying Tic Tac Toe than an untrained agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-diana",
   "metadata": {},
   "source": [
    "### 4.2 Play against Agent L<a id='_42'></a>\n",
    "Play the against the AI agent to evaluate the AI agents ability to play Tic Tac Toe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-overall",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "number_of_games = 1\n",
    "if number_of_games > 0:\n",
    "    \n",
    "    # Play Tic Tac Toe against Agent L\n",
    "    ifile_HL = play_games_and_output_file(1, 1, 'H', 'L', True)\n",
    "    try:\n",
    "        os.remove(ifile_HL)\n",
    "    except:\n",
    "        file_removed = True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-public",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-latitude",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-block",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}